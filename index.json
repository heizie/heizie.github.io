[{"content":"Abstract I\u0026rsquo;ve already built a smart home system based on Home Assistant. The most important task is showing the states of both bathrooms‘ doors sensors because I don’t want to physically check them just like checking other dudes' excretion duration\u0026hellip; And sometimes is just too lazy to take out the phone and check the next bus to the city center, or just too lazy to check the real feel temperature.\nThere is. An ESPHome-based desktop terminal, which shows all needed information.\nComponents The terminal is built based on Wemos D1 Mini, which is using ESP8266 as the main controller. It is conntected with a BME 680 sensor, a ssd1306 OLED, two led for showing doors' states and a button.\nOLED burn-in protection If the normal blue OLED display keeps showing something similar, the pixel of it might be damaged. Therefore, we can let it display some sort of display protection animation or set some mechanism to shut the display down. The funniest thing is, that we have everything to make the display show animation. But the display is way too rubish…the refresh rate, the low resolution. It doesn’t deserve it. So in my third version, I’ve added a button to change the pages of the display and after 10 seconds, the display is shut down.\nPull-up resistor As you might know, the input signal might be disturbed, although it is connected directly by wire. Therefore, we should use a pull-up resistor, which could keep the GPIO voltage always high level. It just simply connects the 3.3v to the input GPIO through a 10 KOhm resistor. If someone presses the button, and because the button resistance is way smaller than the 10KOhm resistor, so the input GPIO voltage is forced to become low level, just like shortcut the GPIO direct to the ground. As an alternative, Wemos D1 Mini provides a build-in pull-up resistor at pin D3 and D4 (D4 with onboard LED). We can also activate them with configs.\nSome dumb things about the timer in ESPHome Timer Normally, once the program is interrupted by pressing the button, another program should run. In our case, ideally, should be either “turn on the display and show the first page, timer initialized” or “switch to the next page, timer refreshed 10 sec.”. However, ESPHome provides only an initializor for the timer. If we keep using  - delay: 10 s after button pressing, tones of the timer are created…So, save some hair for the future. Just set up a timer once the button is pressed…\nbinary_sensor: - platform: gpio pin: 14 id: display_button name: \u0026quot;display button\u0026quot; on_press: then: - if: condition: // use global var flag_dis to distinguish the presses lambda: return id(flag_dis) == 0; then: - display.page.show: page1 - globals.set: id: flag_dis value: '1' - logger.log: \u0026quot;10s timer is set\u0026quot; - delay: 10 s - display.page.show: page_off - globals.set: id: flag_dis value: '0' - logger.log: \u0026quot;time's up\u0026quot; else : display.page.show_next: terminal_display Bugs of display contents? I’ve seen an official example, which uses lambda function to determine the display content.\ndisplay: - platform: ... # ... lambda: |- if (id(my_binary_sensor).state) { it.print(0, 0, id(my_font), \u0026quot;state: ON\u0026quot;); } else { it.print(0, 0, id(my_font), \u0026quot;state: OFF\u0026quot;); } // Shorthand: it.printf(0, 0, id(my_font), \u0026quot;State: %s\u0026quot;, id(my_binary_sensor).state ? \u0026quot;ON\u0026quot; : \u0026quot;OFF\u0026quot;); My suggestion is, don’t do that. Just in my case, it will crash your program in a couple of hours. You could just simply create a new page for shutting down the display\ndisplay: - platform: ssd1306_i2c model: \u0026quot;SSD1306 128x64\u0026quot; id: terminal_display pages: // page to shut down the display - id: page_off lambda: |- it.fill(COLOR_OFF); - id: page1 lambda: |- it.printf(0, 3, id(normal_font), \u0026quot;1. Bus: %.0f min\u0026quot;, id(display_181_frist).state); it.printf(0, 30, id(normal_font), \u0026quot;2. Bus: %.0f min\u0026quot;, id(display_181_second).state); - id: page2 lambda: |- it.printf(0, 2, id(normal_font), \u0026quot;temp. %.01f°C\u0026quot;, id(room_temperature).state); it.printf(0, 30, id(normal_font), \u0026quot;humid. %.01f%%\u0026quot;, id(room_humidity).state); - id: page3 lambda: |- it.printf(0, 2, id(normal_font), \u0026quot;%s\u0026quot;, id(weather_display).state.c_str()); it.printf(0, 30, id(normal_font), \u0026quot;R.F. %.01f°C\u0026quot;, id(display_real_feel).state); Case first version This is some kind of over-engineered design. \r\rSecond version    \r\r \r\r    Final version \r\r","permalink":"https://heizie.github.io/posts/table_terminal/","summary":"Abstract I\u0026rsquo;ve already built a smart home system based on Home Assistant. The most important task is showing the states of both bathrooms‘ doors sensors because I don’t want to physically check them just like checking other dudes' excretion duration\u0026hellip; And sometimes is just too lazy to take out the phone and check the next bus to the city center, or just too lazy to check the real feel temperature.","title":"[After Work] ESP8266 based information terminal"},{"content":"Abstract For detecting deformable linear objects (DLO), such as cables, CNN-based methods are insufficient for industrial use, such as for bin-picking tasks. In this paper, based on testing various baseline models from state of the art (s.o.t.a), the reasons for flawless while detecting cables are found and depending on those, we\u0026rsquo;ve developed a combination of a 2 stage vision Transformer with HTC framework (Fig. 1) as an example to reach the best performance of detecting cable with s.o.t.a.\nWithout bells and whistles, the proposed method obtains 21.5% AP and 4.7% segm AP gains compared to s.o.t.a methods.\n        Fig. 1 The Structure of our proposed method    What, How, Results What  Based on founded technical difficulties of cable detection, a visual Transformer based method is developed. Our method for cable detection achieve 79.9% box and 33.4% segmentation AP.  How  Based on the classes' scales of the target, local spikes on the feature maps are observed. Based on the classes' quantity, special loss function for imbalance dataset is used for testing the assumption (whether the \u0026ldquo;imbalance\u0026rdquo; affect the accuracy) Comparisons between the Swin Transformer and ResNet are used for proving the negative effect of crossing side to side objects. Implemented anchor-based or anchor-free Region Proposal Network (RPN), observed whether the regression distance affects the accuracy. Implemented oriented proposal based (i.a. rotatable box) RPN, observed whether the one-to-one relation between box and segmentation affect the accuracy.  Results         Fig. 2 Demonstration of the performance gains according to each improvement            Fig. 3 Comparisons between our method and the s.o.t.a    Things I\u0026rsquo;ve achieved  Developed anchor relevant modules for 4-dimensional RoI Transformer from scratch Building assumption models according to the failure cases and developed improvements connect to the scenario Designed and managed dataset; Fast implementation and failure analysis with multiple s.o.t.a as the baseline Pytorch based Detectron 2 and MMDetection are used  ","permalink":"https://heizie.github.io/posts/masterthesis/","summary":"Abstract For detecting deformable linear objects (DLO), such as cables, CNN-based methods are insufficient for industrial use, such as for bin-picking tasks. In this paper, based on testing various baseline models from state of the art (s.o.t.a), the reasons for flawless while detecting cables are found and depending on those, we\u0026rsquo;ve developed a combination of a 2 stage vision Transformer with HTC framework (Fig. 1) as an example to reach the best performance of detecting cable with s.","title":"[Master Thesis]Instance Segmentation for Application to Deformable Linear Objects"},{"content":"Abstract For avoiding collision while operating with articulate laparoscopic manipulator system, the position of the instruments should be provided in real-time. Our proposed method provides a reasonable solution for instrument tracking in vivo.   What, How, Results What  A CNN (moded U-Net) based for detecting medical instruments in vivo using binary distribution and gaussian distribution as the label (Fig. 1)         Fig. 1 Labeling of the joins      How  Transformed the model to FP16-format with TensorRT, and loaded by C++ script Accelerated the support-algorithms  Results  Speed optimization: from 8.7 fps to 44 fps (Fig. 2) Accuracy improvement: 25% less pixel error and about 10% higher recall and precision (Fig. 3) Experimented sensor-fusion for a 3D-reconstruction         Fig. 2 Runtime before optimization (blue) and after (green). Left: CNN prediction phase; Right: labeling center extraction              Fig. 3 Recall, Precision, and Pixel error compared to Du et al. 2018    ","permalink":"https://heizie.github.io/posts/semesterarbeit/","summary":"Abstract For avoiding collision while operating with articulate laparoscopic manipulator system, the position of the instruments should be provided in real-time. Our proposed method provides a reasonable solution for instrument tracking in vivo.   What, How, Results What  A CNN (moded U-Net) based for detecting medical instruments in vivo using binary distribution and gaussian distribution as the label (Fig. 1)         Fig.","title":"[Semester Thesis]Image-based tracking of instruments of a laparoscopic manipulator system"}]